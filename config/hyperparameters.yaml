# =============================================================================
# Environment
# =============================================================================
environment:
  rom_path: pokemon_red.gb
  state_path: states/initial.state
  phase_states:
    nav: states/nav      # directory of nav starting states (.state files)
    battle: states/battle  # directory of battle-focused states
    menu: states/menu    # directory of menu-focused states
  headless: false
  emulation_speed: 5
  action_repeat: 24
  release_frame: 8
  max_steps: 2048
  window_title_debug: true

# =============================================================================
# Training
# =============================================================================
training:
  total_steps: 50000
  warmup_steps: 1000
  batch_size: 32
  save_frequency: 2000
  fast_update_frequency: 4
  reward_clip: 5.0
  epsilon:
    start: 0.9
    end: 0.05
    decay: 50000
  replay:
    nav:
      size: 100000
      alpha: 0.2
    battle:
      size: 100000
      alpha: 0.6
    menu:
      size: 100000  # Slightly smaller as menu interactions are faster/less varied
      alpha: 0.5

# =============================================================================
# Rewards
# =============================================================================
rewards:
  # --- Global ---
  step_penalty: -0.01
  reward_clip: 10.0
  catch_pokemon: 5.0
  level_up: 10.0
  heal_success: 3.0
  heal_target: 0.9

  # --- Navigation shaping ---
  new_tile: 0.2
  new_map: 2.0
  wall_bump: -0.1
  stale_penalty: -0.2
  stale_threshold: 120
  nav_menu_open_bonus: 1.0

  # --- Battle shaping ---
  battle_tick: 0.0
  battle_win: 5.0
  battle_loss: -5.0
  battle_loss_threshold: 0.1
  battle_damage: 4.0
  battle_damage_taken: -3.0
  battle_hp_high_bonus: 0.1
  battle_hp_high_threshold: 0.75

  # --- Menu shaping ---
  menu:
    opened_menu: 1.0       # Bonus when entering any menu (bag/PC/party/START)
    open_bonus: 0.2        # Small per-step bonus for staying inside a menu
    cursor_move: 0.1
    correct_target: 1.0
    cursor_on_target: 0.5
    stale_penalty: -0.1
    stale_threshold: 48
    close_penalty: -1.0    # Applied when a menu closes without action (stops spam)
    scale: 0.01            # Normalize raw menu rewards (divide by 100)
    reward_clip: 1.0

    # Tiny-RL menu economics and mart configuration (menu-tiny-rl branch only).
    # mart_maps: optional list of map ids (D35E) that should be treated as Poké Marts.
    # If empty or omitted, the trainer falls back to RAM heuristics (CF7B) to
    # detect when a mart inventory is active instead of assuming every map.
    mart_maps: [42]   # Default to Pallet Town mart so start_in_mart is only true there.
    economy:
      step_penalty: -0.01           # Base per-step penalty
      open_menu_bonus: 0.5          # Reward when menu opens from closed state
      cursor_on_target_bonus: 0.2   # Bonus when cursor is on the sampled target index
      close_penalty: -1.0           # Penalty when menu closes without success

      buy_item_scale: 0.1           # Scaling for rewarding Poké Ball / Potion gains
      buy_item_cap: 0.5             # Cap on buy reward per transition
      sell_nugget_scale: 0.1        # Scaling for rewarding Nugget sales
      sell_nugget_cap: 0.5          # Cap on Nugget sale reward per transition

      low_money_threshold: 2000     # Soft floor for “don’t go broke” shaping
      low_money_penalty: 0.05       # Penalty applied each step when money < threshold

# =============================================================================
# Director
# =============================================================================
director:
  learning_rate: 0.0003
  vision_learning_rate: 0.0001
  update_interval: 128
  num_specialists: 3
  router_hidden_dim: 64

  goal_head_types:
    - explore   # Focus: Uncovering the map
    - train     # Focus: Leveling up and fighting
    - survive   # Focus: Healing and Party Management
    - menu      # Focus: Deterministic menu interactions (bag, party, options)

  goal_bias:
    explore: 0.6
    train: 0.3
    survive: 0.1  # Should be reactive (triggered by low HP state)

  goal_specialist_map:
    explore: 0  # Navigation Brain
    train: 1    # Battle Brain
    survive: 2  # Menu Brain or Navigation Brain (if no items)
    menu: 2     # Explicit menu goal routing

  goals:
    explore:
      priority: 0
      novel_states: 10
      max_steps: 2048
      reward_focus: "new_tile"
    train:
      priority: 10
      xp_gained: 100
      battles_won: 1
      max_steps: 1024
      reward_focus: "level_up"
    survive:
      priority: 5
      hp_threshold: 0.3
      hp_target: 0.9
      max_steps: 512
      reward_focus: "heal_success"
    menu:
      priority: 5
      max_steps: 128
      menu_target: 0
      cursor_row: 0
      cursor_col: 0
      reward_focus: "menu"

  graph:
    max_nodes: 5000
    downsample_size: 8
    quantization_step: 32

# =============================================================================
# Specialists
# =============================================================================
specialists:
  navigation:
    learning_rate: 0.00001
    gamma: 0.98
    allowed_actions: [0, 1, 2, 3, 4, 5]  # Arrows, A, B

  battle:
    learning_rate: 0.0001
    gamma: 0.99
    allowed_actions: [0, 1, 2, 3, 4, 5]  # Arrows, A, B

  menu:
    learning_rate: 0.0000005
    gamma: 0.95  # Lower gamma: Menu tasks are short-horizon
    hidden_dim: 256
    goal_dim: 4
    allowed_actions: [0, 1, 2, 3, 4, 5, 6]  # Up, Down, Left, Right, A, B, Start
    goal_encoding:
      menu_target_scale: 8.0
      cursor_row_scale: 8.0
      cursor_col_scale: 8.0
      open_flag_value: 1.0
      reward_weights:
        correct_target: 1.0
        cursor_on_target: 0.5
        stale_penalty: -0.1
        stale_threshold: 48
        close_penalty: -0.1
    goal_defaults:
      menu_target: 0
      cursor_row: 0
      cursor_col: 0
